{
  "hash": "890e673b83235add22970c79bad53963",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Latent Class Analysis in R: A Step-by-Step Guide\"\nsubtitle: \"Using poLCA with Fit Statistics and Model Interpretation\"\nauthor: \"David R. Pletta, PhD, MPH\"\ndate: today\nformat:\n  html:\n    toc: true\n    toc-depth: 3\n    code-fold: false\n    code-tools: true\n    theme: cosmo\n    highlight-style: github\nexecute:\n  warning: false\n  message: false\n---\n\n## Introduction\n\n**Latent Class Analysis (LCA)** is a statistical method used to identify unobserved (latent) subgroups within a population based on patterns of responses to categorical indicator variables. Unlike cluster analysis, LCA is model-based and provides probabilistic class membership.\n\nThis tutorial will walk you through:\n\n1. Setting up and running LCA models in R\n2. Comparing models with different numbers of classes\n3. Calculating and interpreting fit statistics\n4. Interpreting your final model results\n\n## Setup\n\n### Install and Load Packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Install packages if needed (uncomment to run)\n# install.packages(c(\"poLCA\", \"tidyverse\", \"knitr\", \"kableExtra\", \"patchwork\",\n#                    \"randomForest\", \"fastshap\"))\n\n# Load required packages\nlibrary(poLCA)       # Main LCA package\nlibrary(tidyverse)   # Data manipulation and visualization\nlibrary(knitr)       # Tables\nlibrary(kableExtra)  # Pretty tables\nlibrary(patchwork)   # Combining multiple plots\n```\n:::\n\n\n### The Dataset\n\nWe'll use the indicator variables from the `cheating` dataset in the `poLCA` package, combined with **synthetic demographic data** to create a more realistic educational research scenario. This simulates a study of cheating behaviors among K-12 students.\n\n#### Indicator Variables (from cheating dataset)\n\n| Variable | Description |\n|----------|-------------|\n| **LIEEXAM** | Lied to avoid taking an exam (1 = No, 2 = Yes) |\n| **LIEPAPER** | Lied to avoid handing a paper in on time (1 = No, 2 = Yes) |\n| **FRAUD** | Purchased a term paper to hand in as own work (1 = No, 2 = Yes) |\n| **COPYEXAM** | Copied answers during an exam from someone sitting nearby (1 = No, 2 = Yes) |\n\n#### Synthetic Demographic Variables\n\n| Variable | Description |\n|----------|-------------|\n| **AGE** | Student age (10-18 years) |\n| **SCHOOL** | School level (Elementary, Middle School, High School) |\n| **GPA** | Grade point average (1.0-4.0 scale) |\n| **GPA_ZSCORE** | Z-scored GPA within school level |\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load the cheating dataset and keep only indicator variables\ndata(cheating)\nn <- nrow(cheating)\n\n# Set seed for reproducibility of synthetic data\nset.seed(123)\n\n# Generate synthetic AGE (10-18) with realistic school distribution\n# Slight skew toward middle/high school ages\nage_probs <- c(rep(0.08, 3),   # Ages 10-12 (Elementary)\n               rep(0.12, 3),   # Ages 13-15 (Middle)\n               rep(0.13, 3))   # Ages 16-18 (High School)\nage_probs <- age_probs / sum(age_probs)\nAGE <- sample(10:18, n, replace = TRUE, prob = age_probs)\n\n# Create SCHOOL based on AGE\nSCHOOL <- case_when(\n  AGE >= 10 & AGE <= 12 ~ \"Elementary\",\n  AGE >= 13 & AGE <= 15 ~ \"Middle School\",\n  AGE >= 16 & AGE <= 18 ~ \"High School\"\n)\nSCHOOL <- factor(SCHOOL, levels = c(\"Elementary\", \"Middle School\", \"High School\"))\n\n# Generate GPA with school-clustered means and variances\n# Rationale: GPA distributions tend to have greater variance in higher grades\n# Elementary: tighter distribution around higher mean (less differentiation)\n# High School: wider distribution (more differentiation in performance)\n\ngenerate_gpa <- function(school) {\n  gpa <- case_when(\n    school == \"Elementary\" ~ rnorm(1, mean = 3.2, sd = 0.4),\n    school == \"Middle School\" ~ rnorm(1, mean = 2.9, sd = 0.6),\n    school == \"High School\" ~ rnorm(1, mean = 2.7, sd = 0.8)\n  )\n  # Bound GPA to 1.0-4.0 range\n  pmin(pmax(gpa, 1.0), 4.0)\n}\n\nGPA <- sapply(SCHOOL, generate_gpa)\n\n# Create GPA_ZSCORE within school clusters\n# This standardizes GPA relative to peers at the same school level\ngpa_df <- data.frame(SCHOOL = SCHOOL, GPA = GPA)\ngpa_df <- gpa_df %>%\n  group_by(SCHOOL) %>%\n  mutate(\n    GPA_ZSCORE = (GPA - mean(GPA)) / sd(GPA)\n  ) %>%\n  ungroup()\n\nGPA_ZSCORE <- gpa_df$GPA_ZSCORE\n\n# Combine cheating indicators with synthetic demographics\nstudent_data <- cheating %>%\n  select(LIEEXAM, LIEPAPER, FRAUD, COPYEXAM) %>%\n  mutate(\n    AGE = AGE,\n    SCHOOL = SCHOOL,\n    GPA = round(GPA, 2),\n    GPA_ZSCORE = round(GPA_ZSCORE, 3)\n  )\n\n# View the first few rows\nhead(student_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  LIEEXAM LIEPAPER FRAUD COPYEXAM AGE        SCHOOL  GPA GPA_ZSCORE\n1       1        1     1        1  18   High School 3.13      0.704\n2       1        1     1        1  12    Elementary 2.47     -1.884\n3       1        1     1        1  15 Middle School 3.48      1.071\n4       1        1     1        1  11    Elementary 3.34      0.200\n5       1        1     1        1  10    Elementary 2.90     -0.863\n6       1        1     1        1  17   High School 1.91     -0.826\n```\n\n\n:::\n\n```{.r .cell-code}\n# Check the structure\nstr(student_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t319 obs. of  8 variables:\n $ LIEEXAM   : num  1 1 1 1 1 1 1 1 1 1 ...\n $ LIEPAPER  : num  1 1 1 1 1 1 1 1 1 1 ...\n $ FRAUD     : num  1 1 1 1 1 1 1 1 1 1 ...\n $ COPYEXAM  : num  1 1 1 1 1 1 1 1 1 1 ...\n $ AGE       : int  18 12 15 11 10 17 14 11 14 15 ...\n $ SCHOOL    : Factor w/ 3 levels \"Elementary\",\"Middle School\",..: 3 1 2 1 1 3 2 1 2 2 ...\n $ GPA       : num  3.13 2.47 3.48 3.34 2.9 1.91 2.78 2.85 2.87 3.98 ...\n $ GPA_ZSCORE: num  0.704 -1.884 1.071 0.2 -0.863 ...\n```\n\n\n:::\n:::\n\n\n**Important Note for poLCA:** All indicator variables must be coded as positive integers starting at 1 (not 0). The cheating behavior variables are already correctly coded (1 = No, 2 = Yes).\n\n### Exploring the Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Response frequencies for cheating behaviors\nstudent_data %>%\n  select(LIEEXAM, LIEPAPER, FRAUD, COPYEXAM) %>%\n  pivot_longer(everything(), names_to = \"Variable\", values_to = \"Response\") %>%\n  mutate(Response = factor(Response, labels = c(\"No\", \"Yes\"))) %>%\n  count(Variable, Response) %>%\n  pivot_wider(names_from = Response, values_from = n) %>%\n  mutate(Pct_Yes = round(Yes / (No + Yes) * 100, 1)) %>%\n  kable(caption = \"Response Frequencies for Cheating Behaviors\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Response Frequencies for Cheating Behaviors</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Variable </th>\n   <th style=\"text-align:right;\"> No </th>\n   <th style=\"text-align:right;\"> Yes </th>\n   <th style=\"text-align:right;\"> Pct_Yes </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> COPYEXAM </td>\n   <td style=\"text-align:right;\"> 251 </td>\n   <td style=\"text-align:right;\"> 68 </td>\n   <td style=\"text-align:right;\"> 21.3 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> FRAUD </td>\n   <td style=\"text-align:right;\"> 298 </td>\n   <td style=\"text-align:right;\"> 21 </td>\n   <td style=\"text-align:right;\"> 6.6 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> LIEEXAM </td>\n   <td style=\"text-align:right;\"> 285 </td>\n   <td style=\"text-align:right;\"> 34 </td>\n   <td style=\"text-align:right;\"> 10.7 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> LIEPAPER </td>\n   <td style=\"text-align:right;\"> 281 </td>\n   <td style=\"text-align:right;\"> 38 </td>\n   <td style=\"text-align:right;\"> 11.9 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visualize demographic distributions\np1 <- ggplot(student_data, aes(x = AGE)) +\n  geom_bar(fill = \"steelblue\", alpha = 0.7) +\n  labs(title = \"Age Distribution\", x = \"Age\", y = \"Count\") +\n  theme_minimal()\n\np2 <- ggplot(student_data, aes(x = SCHOOL)) +\n  geom_bar(fill = \"darkgreen\", alpha = 0.7) +\n  labs(title = \"School Level Distribution\", x = \"\", y = \"Count\") +\n  theme_minimal()\n\np3 <- ggplot(student_data, aes(x = GPA, fill = SCHOOL)) +\n  geom_density(alpha = 0.5) +\n  labs(title = \"GPA Distribution by School Level\",\n       x = \"GPA\", y = \"Density\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\np1 | p2 | p3\n```\n\n::: {.cell-output-display}\n![](lca-walkthrough_files/figure-html/explore-demographics-1.png){width=960}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Summary of GPA by school level\nstudent_data %>%\n  group_by(SCHOOL) %>%\n  summarize(\n    N = n(),\n    Mean_GPA = mean(GPA),\n    SD_GPA = sd(GPA),\n    Min_GPA = min(GPA),\n    Max_GPA = max(GPA),\n    Mean_ZSCORE = mean(GPA_ZSCORE)  # Should be ~0 within each group\n  ) %>%\n  kable(digits = 3, caption = \"GPA Statistics by School Level\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>GPA Statistics by School Level</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> SCHOOL </th>\n   <th style=\"text-align:right;\"> N </th>\n   <th style=\"text-align:right;\"> Mean_GPA </th>\n   <th style=\"text-align:right;\"> SD_GPA </th>\n   <th style=\"text-align:right;\"> Min_GPA </th>\n   <th style=\"text-align:right;\"> Max_GPA </th>\n   <th style=\"text-align:right;\"> Mean_ZSCORE </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Elementary </td>\n   <td style=\"text-align:right;\"> 72 </td>\n   <td style=\"text-align:right;\"> 3.261 </td>\n   <td style=\"text-align:right;\"> 0.421 </td>\n   <td style=\"text-align:right;\"> 2.17 </td>\n   <td style=\"text-align:right;\"> 4 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Middle School </td>\n   <td style=\"text-align:right;\"> 123 </td>\n   <td style=\"text-align:right;\"> 2.847 </td>\n   <td style=\"text-align:right;\"> 0.593 </td>\n   <td style=\"text-align:right;\"> 1.00 </td>\n   <td style=\"text-align:right;\"> 4 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> High School </td>\n   <td style=\"text-align:right;\"> 124 </td>\n   <td style=\"text-align:right;\"> 2.570 </td>\n   <td style=\"text-align:right;\"> 0.794 </td>\n   <td style=\"text-align:right;\"> 1.00 </td>\n   <td style=\"text-align:right;\"> 4 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n## Running LCA Models\n\n### Step 1: Define the Model Formula\n\nIn `poLCA`, we specify which variables are indicators of the latent class using a formula. All indicators go on the left side of `~` and `1` goes on the right (meaning no covariates predicting class membership).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define the LCA formula\n# All four cheating behaviors are indicators of the latent class\nlca_formula <- cbind(LIEEXAM, LIEPAPER, FRAUD, COPYEXAM) ~ 1\n```\n:::\n\n\n### Step 2: Fit Models with Different Numbers of Classes\n\nA key step in LCA is determining the optimal number of classes. We'll fit models with 1, 2, 3, and 4 classes and compare them. The **1-class model serves as a baseline** - it assumes no latent heterogeneity (all individuals come from the same distribution). Comparing it to multi-class models demonstrates whether latent class structure exists in the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set seed for reproducibility\nset.seed(42)\n\n# Fit models with 1-4 classes\n# nrep = 10 runs the model 10 times with different starting values\n# to avoid local maxima (increase for final analyses)\n\n# 1-class model: No latent heterogeneity (baseline model)\nmodel_1 <- poLCA(lca_formula, data = student_data, nclass = 1,\n                 nrep = 1, verbose = FALSE)  # nrep=1 since 1-class has no local maxima issue\n\nmodel_2 <- poLCA(lca_formula, data = student_data, nclass = 2,\n                 nrep = 10, verbose = FALSE)\n\nmodel_3 <- poLCA(lca_formula, data = student_data, nclass = 3,\n                 nrep = 10, verbose = FALSE)\n\nmodel_4 <- poLCA(lca_formula, data = student_data, nclass = 4,\n                 nrep = 10, verbose = FALSE)\n\n# Store models in a list for easier comparison\nmodels <- list(model_1, model_2, model_3, model_4)\nnames(models) <- c(\"1-Class\", \"2-Class\", \"3-Class\", \"4-Class\")\n```\n:::\n\n\n## Fit Statistics\n\n### Understanding Key Fit Indices\n\nWhen comparing LCA models, we examine several fit statistics:\n\n| Statistic | Description | What to Look For |\n|-----------|-------------|------------------|\n| **AIC** | Akaike Information Criterion | Lower is better |\n| **BIC** | Bayesian Information Criterion | Lower is better; often preferred for class enumeration |\n| **Entropy** | Quality of classification | Higher is better (closer to 1.0) |\n| **AvePP** | Average Posterior Probability | Higher is better (> 0.70 acceptable, > 0.80 good) |\n| **OCC** | Odds of Correct Classification | Higher is better (> 5.0 indicates good separation) |\n| **BLRT** | Bootstrap Likelihood Ratio Test | Significant p-value suggests k classes fit better than k-1 |\n\n### Calculate Fit Statistics\n\n#### Basic Fit Statistics (AIC, BIC, Log-Likelihood)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Function to extract basic fit statistics\nextract_basic_fit <- function(model, n_class) {\n  data.frame(\n    Classes = n_class,\n    LogLik = model$llik,\n    AIC = model$aic,\n    BIC = model$bic,\n    N_parameters = model$npar,\n    df = model$resid.df\n  )\n}\n\n# Extract for all models\nbasic_fit <- bind_rows(\n  extract_basic_fit(model_1, 1),\n  extract_basic_fit(model_2, 2),\n  extract_basic_fit(model_3, 3),\n  extract_basic_fit(model_4, 4)\n)\n\n# Display table\nbasic_fit %>%\n  kable(digits = 2, caption = \"Basic Fit Statistics\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Basic Fit Statistics</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> Classes </th>\n   <th style=\"text-align:right;\"> LogLik </th>\n   <th style=\"text-align:right;\"> AIC </th>\n   <th style=\"text-align:right;\"> BIC </th>\n   <th style=\"text-align:right;\"> N_parameters </th>\n   <th style=\"text-align:right;\"> df </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> -467.44 </td>\n   <td style=\"text-align:right;\"> 942.88 </td>\n   <td style=\"text-align:right;\"> 957.94 </td>\n   <td style=\"text-align:right;\"> 4 </td>\n   <td style=\"text-align:right;\"> 11 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> -440.03 </td>\n   <td style=\"text-align:right;\"> 898.05 </td>\n   <td style=\"text-align:right;\"> 931.94 </td>\n   <td style=\"text-align:right;\"> 9 </td>\n   <td style=\"text-align:right;\"> 6 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:right;\"> -436.24 </td>\n   <td style=\"text-align:right;\"> 900.47 </td>\n   <td style=\"text-align:right;\"> 953.18 </td>\n   <td style=\"text-align:right;\"> 14 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 4 </td>\n   <td style=\"text-align:right;\"> -436.15 </td>\n   <td style=\"text-align:right;\"> 910.29 </td>\n   <td style=\"text-align:right;\"> 981.83 </td>\n   <td style=\"text-align:right;\"> 19 </td>\n   <td style=\"text-align:right;\"> -4 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n#### Entropy\n\nEntropy measures the quality of classification. It ranges from 0 to 1, with values closer to 1 indicating clearer class separation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Function to calculate entropy\ncalculate_entropy <- function(model) {\n  # Get posterior probabilities\n  posterior <- model$posterior\n  K <- ncol(posterior)\n\n  # For 1-class model, entropy is undefined (or trivially 1.0)\n  # since there's no uncertainty in classification\n  if (K == 1) {\n    return(1.0)  # Perfect \"classification\" when there's only one class\n  }\n\n  # Calculate entropy\n  # Formula: 1 - (sum of -p*log(p)) / (N * log(K))\n  N <- nrow(posterior)\n\n  # Calculate the sum of -p*log(p) for each observation\n  # Add small value to avoid log(0)\n  entropy_sum <- sum(-posterior * log(posterior + 1e-10))\n\n  # Relative entropy\n  entropy <- 1 - (entropy_sum / (N * log(K)))\n\n  return(entropy)\n}\n\n# Calculate entropy for each model\nentropy_values <- sapply(models, calculate_entropy)\n\n# Display\nentropy_df <- data.frame(\n  Model = names(entropy_values),\n  Entropy = round(entropy_values, 3)\n)\n\nentropy_df %>%\n  kable(caption = \"Entropy Values by Model\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Entropy Values by Model</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">  </th>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:right;\"> Entropy </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 1-Class </td>\n   <td style=\"text-align:left;\"> 1-Class </td>\n   <td style=\"text-align:right;\"> 1.000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2-Class </td>\n   <td style=\"text-align:left;\"> 2-Class </td>\n   <td style=\"text-align:right;\"> 0.737 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 3-Class </td>\n   <td style=\"text-align:left;\"> 3-Class </td>\n   <td style=\"text-align:right;\"> 0.889 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 4-Class </td>\n   <td style=\"text-align:left;\"> 4-Class </td>\n   <td style=\"text-align:right;\"> 0.620 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n**Interpretation Guidelines for Entropy:**\n\n- \\> 0.80: High classification accuracy\n- 0.60 - 0.80: Medium classification accuracy\n- \\< 0.60: Low classification accuracy (classes may not be well-separated)\n\n#### Average Posterior Probability (AvePP)\n\nAvePP is the average of the maximum posterior probabilities within each class. Higher values indicate that individuals are classified with greater certainty.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Function to calculate AvePP for each class\ncalculate_avepp <- function(model) {\n  # Get posterior probabilities and predicted class\n  posterior <- model$posterior\n  predicted_class <- model$predclass\n  n_classes <- ncol(posterior)\n\n  # For 1-class model, AvePP is trivially 1.0\n  # (everyone is assigned to the same class with probability 1)\n  if (n_classes == 1) {\n    return(list(\n      by_class = 1.0,\n      overall = 1.0\n    ))\n  }\n\n  # Calculate AvePP for each class\n  avepp_by_class <- numeric(n_classes)\n\n  for (k in 1:n_classes) {\n    # Get posterior probabilities for individuals assigned to class k\n    class_members <- predicted_class == k\n    if (sum(class_members) > 0) {\n      avepp_by_class[k] <- mean(posterior[class_members, k])\n    }\n  }\n\n  return(list(\n    by_class = avepp_by_class,\n    overall = mean(avepp_by_class)\n  ))\n}\n\n# Calculate AvePP for each model\navepp_results <- lapply(models, calculate_avepp)\n\n# Create summary table\navepp_summary <- data.frame(\n  Model = names(models),\n  Overall_AvePP = sapply(avepp_results, function(x) round(x$overall, 3))\n)\n\navepp_summary %>%\n  kable(caption = \"Average Posterior Probability (AvePP)\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Average Posterior Probability (AvePP)</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">  </th>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:right;\"> Overall_AvePP </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 1-Class </td>\n   <td style=\"text-align:left;\"> 1-Class </td>\n   <td style=\"text-align:right;\"> 1.000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2-Class </td>\n   <td style=\"text-align:left;\"> 2-Class </td>\n   <td style=\"text-align:right;\"> 0.870 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 3-Class </td>\n   <td style=\"text-align:left;\"> 3-Class </td>\n   <td style=\"text-align:right;\"> 0.887 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 4-Class </td>\n   <td style=\"text-align:left;\"> 4-Class </td>\n   <td style=\"text-align:right;\"> 0.775 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n**Interpretation Guidelines for AvePP:**\n\n- \\> 0.80: Good classification certainty\n- 0.70 - 0.80: Acceptable classification certainty\n- \\< 0.70: Poor classification certainty\n\n#### Detailed AvePP by Class\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Show AvePP by class for each model\ncat(\"AvePP by Class:\\n\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAvePP by Class:\n```\n\n\n:::\n\n```{.r .cell-code}\nfor (model_name in names(models)) {\n  cat(model_name, \"Model:\\n\")\n  avepp <- avepp_results[[model_name]]$by_class\n  for (k in seq_along(avepp)) {\n    cat(sprintf(\"  Class %d: %.3f\\n\", k, avepp[k]))\n  }\n  cat(\"\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n1-Class Model:\n  Class 1: 1.000\n\n2-Class Model:\n  Class 1: 0.965\n  Class 2: 0.775\n\n3-Class Model:\n  Class 1: 0.889\n  Class 2: 0.798\n  Class 3: 0.973\n\n4-Class Model:\n  Class 1: 0.738\n  Class 2: 0.966\n  Class 3: 0.565\n  Class 4: 0.831\n```\n\n\n:::\n:::\n\n\n#### Odds of Correct Classification (OCC)\n\nOCC indicates how much better the model's classification is compared to random assignment. Values > 5 suggest good class separation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Function to calculate OCC for each class\ncalculate_occ <- function(model) {\n  posterior <- model$posterior\n  predicted_class <- model$predclass\n  class_sizes <- model$P  # Prior probabilities (class proportions)\n  n_classes <- ncol(posterior)\n\n  # For 1-class model, OCC is not meaningful (no classification to evaluate)\n  # Return NA to indicate this\n  if (n_classes == 1) {\n    return(list(\n      by_class = NA,\n      minimum = NA\n    ))\n  }\n\n  occ_by_class <- numeric(n_classes)\n\n  for (k in 1:n_classes) {\n    class_members <- predicted_class == k\n    if (sum(class_members) > 0) {\n      avepp_k <- mean(posterior[class_members, k])\n      # OCC formula: (AvePP / (1 - AvePP)) / (class_size / (1 - class_size))\n      occ_by_class[k] <- (avepp_k / (1 - avepp_k)) /\n                         (class_sizes[k] / (1 - class_sizes[k]))\n    }\n  }\n\n  return(list(\n    by_class = occ_by_class,\n    minimum = min(occ_by_class)\n  ))\n}\n\n# Calculate OCC for each model\nocc_results <- lapply(models, calculate_occ)\n\n# Create summary table\nocc_summary <- data.frame(\n  Model = names(models),\n  Min_OCC = sapply(occ_results, function(x) round(x$minimum, 2))\n)\n\nocc_summary %>%\n  kable(caption = \"Minimum Odds of Correct Classification (OCC)\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Minimum Odds of Correct Classification (OCC)</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">  </th>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:right;\"> Min_OCC </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 1-Class </td>\n   <td style=\"text-align:left;\"> 1-Class </td>\n   <td style=\"text-align:right;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2-Class </td>\n   <td style=\"text-align:left;\"> 2-Class </td>\n   <td style=\"text-align:right;\"> 5.23 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 3-Class </td>\n   <td style=\"text-align:left;\"> 3-Class </td>\n   <td style=\"text-align:right;\"> 4.30 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 4-Class </td>\n   <td style=\"text-align:left;\"> 4-Class </td>\n   <td style=\"text-align:right;\"> 2.14 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n**Interpretation Guidelines for OCC:**\n\n- \\> 5.0: Good class separation\n- 1.0 - 5.0: Moderate class separation\n- \\< 1.0: Poor class separation (no better than chance)\n\n#### Detailed OCC by Class\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Show OCC by class for each model\ncat(\"OCC by Class:\\n\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOCC by Class:\n```\n\n\n:::\n\n```{.r .cell-code}\nfor (model_name in names(models)) {\n  cat(model_name, \"Model:\\n\")\n  occ <- occ_results[[model_name]]$by_class\n  for (k in seq_along(occ)) {\n    cat(sprintf(\"  Class %d: %.2f\\n\", k, occ[k]))\n  }\n  cat(\"\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n1-Class Model:\n  Class 1: NA\n\n2-Class Model:\n  Class 1: 5.23\n  Class 2: 18.06\n\n3-Class Model:\n  Class 1: 137.76\n  Class 2: 72.92\n  Class 3: 4.30\n\n4-Class Model:\n  Class 1: 19.90\n  Class 2: 609.26\n  Class 3: 8.37\n  Class 4: 2.14\n```\n\n\n:::\n:::\n\n\n### Bootstrap Likelihood Ratio Test (BLRT)\n\nThe BLRT compares a model with k classes to a model with k-1 classes. A significant p-value suggests the k-class model fits significantly better.\n\n**Note:** BLRT is computationally intensive. We'll demonstrate with a small number of bootstrap samples. For publication, use at least 100-500 bootstrap samples.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Function to perform Bootstrap LRT\n# Compares k-class model to (k-1)-class model\nblrt_test <- function(formula, data, k, n_boot = 100, seed = 42) {\n  set.seed(seed)\n\n  # Fit the null model (k-1 classes) and alternative model (k classes)\n  model_null <- poLCA(formula, data = data, nclass = k - 1,\n                      nrep = 5, verbose = FALSE)\n  model_alt <- poLCA(formula, data = data, nclass = k,\n                     nrep = 5, verbose = FALSE)\n\n  # Observed LRT statistic\n  lrt_observed <- 2 * (model_alt$llik - model_null$llik)\n\n  # Bootstrap under the null model\n  n <- nrow(data)\n  lrt_boot <- numeric(n_boot)\n\n  for (b in 1:n_boot) {\n    # Generate bootstrap sample under null model\n    # Sample class memberships based on null model probabilities\n    class_probs <- model_null$P\n    classes <- sample(1:(k-1), n, replace = TRUE, prob = class_probs)\n\n    # Generate responses based on null model item probabilities\n    boot_data <- data\n    for (j in 1:length(model_null$probs)) {\n      var_name <- names(model_null$probs)[j]\n      n_categories <- length(model_null$probs[[j]][1,])\n\n      for (i in 1:n) {\n        class_i <- classes[i]\n        probs_i <- model_null$probs[[j]][class_i, ]\n        boot_data[i, var_name] <- sample(1:n_categories, 1, prob = probs_i)\n      }\n    }\n\n    # Fit both models to bootstrap sample\n    boot_null <- tryCatch(\n      poLCA(formula, data = boot_data, nclass = k - 1,\n            nrep = 3, verbose = FALSE),\n      error = function(e) NULL\n    )\n\n    boot_alt <- tryCatch(\n      poLCA(formula, data = boot_data, nclass = k,\n            nrep = 3, verbose = FALSE),\n      error = function(e) NULL\n    )\n\n    if (!is.null(boot_null) && !is.null(boot_alt)) {\n      lrt_boot[b] <- 2 * (boot_alt$llik - boot_null$llik)\n    } else {\n      lrt_boot[b] <- NA\n    }\n  }\n\n  # Calculate p-value\n  lrt_boot <- na.omit(lrt_boot)\n  p_value <- mean(lrt_boot >= lrt_observed)\n\n  return(list(\n    lrt_statistic = lrt_observed,\n    p_value = p_value,\n    n_valid_boot = length(lrt_boot)\n  ))\n}\n\n# Run BLRT for 1 vs 2, 2 vs 3, and 3 vs 4 classes\n# Using fewer bootstrap samples for demonstration (increase for real analysis)\ncat(\"Running Bootstrap LRT (this may take a moment)...\\n\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRunning Bootstrap LRT (this may take a moment)...\n```\n\n\n:::\n\n```{.r .cell-code}\nblrt_1v2 <- blrt_test(lca_formula, student_data, k = 2, n_boot = 50)\nblrt_2v3 <- blrt_test(lca_formula, student_data, k = 3, n_boot = 50)\nblrt_3v4 <- blrt_test(lca_formula, student_data, k = 4, n_boot = 50)\n\n# Display results\n# Convention: \"k vs k-1\" means testing if k-class model fits better than k-1 class model\nblrt_results <- data.frame(\n  Comparison = c(\"2 vs 1 Classes\", \"3 vs 2 Classes\", \"4 vs 3 Classes\"),\n  LRT_Statistic = c(blrt_1v2$lrt_statistic, blrt_2v3$lrt_statistic, blrt_3v4$lrt_statistic),\n  p_value = c(blrt_1v2$p_value, blrt_2v3$p_value, blrt_3v4$p_value),\n  N_Bootstrap = c(blrt_1v2$n_valid_boot, blrt_2v3$n_valid_boot, blrt_3v4$n_valid_boot)\n)\n\nblrt_results %>%\n  kable(digits = 4, caption = \"Bootstrap Likelihood Ratio Test Results\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Bootstrap Likelihood Ratio Test Results</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Comparison </th>\n   <th style=\"text-align:right;\"> LRT_Statistic </th>\n   <th style=\"text-align:right;\"> p_value </th>\n   <th style=\"text-align:right;\"> N_Bootstrap </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 2 vs 1 Classes </td>\n   <td style=\"text-align:right;\"> 54.8222 </td>\n   <td style=\"text-align:right;\"> 0.00 </td>\n   <td style=\"text-align:right;\"> 50 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 3 vs 2 Classes </td>\n   <td style=\"text-align:right;\"> 7.5831 </td>\n   <td style=\"text-align:right;\"> 0.08 </td>\n   <td style=\"text-align:right;\"> 50 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 4 vs 3 Classes </td>\n   <td style=\"text-align:right;\"> 0.1888 </td>\n   <td style=\"text-align:right;\"> 0.96 </td>\n   <td style=\"text-align:right;\"> 50 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n**Interpretation:** A significant p-value (typically < 0.05) suggests that the model with more classes fits significantly better than the model with fewer classes. The **2 vs 1 class comparison is critical** - a significant result here demonstrates that the 2-class model is a significant improvement over the 1-class (no heterogeneity) model, justifying the use of LCA.\n\n::: {.callout-note}\n## Why LRT Statistics Can Vary Dramatically Between Comparisons\n\nYou may notice large differences in LRT statistics across comparisons (e.g., 7.58 for 2 vs 3 classes, but only 0.19 for 3 vs 4 classes). This is expected and reflects the underlying data structure:\n- The LRT statistic equals 2 Ã— (Log-likelihood~k~ - Log-likelihood~k-1~)\n- When an additional class captures a meaningful subgroup, the log-likelihood improves substantially, producing a larger LRT\n- When an additional class adds no new information, the log-likelihoods are nearly identical, producing an LRT close to zero\n\nA very small LRT statistic (near zero) with a large p-value indicates that the more complex model provides essentially no improvement over the simpler one. This is valuable information for model selection.\n:::\n\n### Optimized BLRT for Large Datasets\n\nThe `blrt_test` function above uses a nested loop to generate bootstrap samples, which is intuitive for learning but can be slow for large datasets ($N > 1000$). For larger datasets, using `poLCA.simdata()` is significantly faster because it generates data directly from the model parameters without iterating through every row in R.\n\n**When to use this optimized approach:**\n\n1. **Large Sample Sizes:** When your dataset has thousands of observations.\n2. **Many Bootstrap Replicates:** When you need to run 500+ bootstraps for publication-quality p-values.\n3. **Performance Bottlenecks:** If the standard function is taking too long to run.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set the eval statement above to false to skip\n\n# Optimized BLRT function using poLCA.simdata() for data generation\n# poLCA.simdata() generates data directly from model parameters,\n# which is much faster than row-by-row sampling\nblrt_test_optimized <- function(formula, data, k, n_boot = 100, seed = 42) {\n  set.seed(seed)\n  n <- nrow(data)\n\n  # Fit models to observed data\n  model_null <- poLCA(formula, data = data, nclass = k - 1,\n                      nrep = 10, verbose = FALSE)\n  model_alt <- poLCA(formula, data = data, nclass = k,\n                     nrep = 10, verbose = FALSE)\n\n  # Get the variable names from the fitted model\n  var_names <- names(model_null$probs)\n\n  lrt_observed <- 2 * (model_alt$llik - model_null$llik)\n  lrt_boot <- numeric(n_boot)\n\n  for (b in 1:n_boot) {\n    # Use poLCA.simdata() to generate data efficiently from Null model parameters\n    # Key arguments:\n    #   N = sample size\n    #   probs = list of class-conditional response probability matrices\n    #   P = class mixing proportions\n    sim_result <- poLCA.simdata(N = n,\n                                 probs = model_null$probs,\n                                 P = model_null$P)\n\n    # poLCA.simdata() returns data with Y columns - rename to match original formula\n    boot_data <- sim_result$dat\n    # The Y columns correspond to the manifest variables in order\n    y_cols <- grep(\"^Y\", names(boot_data), value = TRUE)\n    if (length(y_cols) == length(var_names)) {\n      names(boot_data)[names(boot_data) %in% y_cols] <- var_names\n    }\n\n    # Fit models to bootstrap data\n    # Note: Reduced nrep for speed; increase for real analysis\n    boot_null <- tryCatch(\n      poLCA(formula, data = boot_data, nclass = k - 1,\n            nrep = 1, verbose = FALSE),\n      error = function(e) NULL\n    )\n\n    boot_alt <- tryCatch(\n      poLCA(formula, data = boot_data, nclass = k,\n            nrep = 1, verbose = FALSE),\n      error = function(e) NULL\n    )\n\n    if (!is.null(boot_null) && !is.null(boot_alt)) {\n      lrt_boot[b] <- 2 * (boot_alt$llik - boot_null$llik)\n    } else {\n      lrt_boot[b] <- NA\n    }\n  }\n\n  lrt_boot <- na.omit(lrt_boot)\n  p_value <- mean(lrt_boot >= lrt_observed)\n\n  return(list(\n    lrt_statistic = lrt_observed,\n    p_value = p_value,\n    n_valid_boot = length(lrt_boot)\n  ))\n}\n\n# Run optimized BLRT for 2 vs 1 class comparison\ncat(\"Running optimized Bootstrap LRT...\\n\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRunning optimized Bootstrap LRT...\n```\n\n\n:::\n\n```{.r .cell-code}\nblrt_opt_2v1 <- blrt_test_optimized(lca_formula, student_data, k = 2, n_boot = 100)\n\ncat(sprintf(\"2 vs 1 Classes (Optimized): LRT = %.4f, p = %.4f (n_boot = %d)\\n\",\n            blrt_opt_2v1$lrt_statistic, blrt_opt_2v1$p_value, blrt_opt_2v1$n_valid_boot))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n2 vs 1 Classes (Optimized): LRT = 54.8222, p = 0.0000 (n_boot = 99)\n```\n\n\n:::\n:::\n\n\n::: {.callout-tip}\n## About poLCA.simdata()\n\nThe `poLCA.simdata()` function generates simulated data from specified LCA model parameters. Key arguments:\n\n- **N**: Number of observations to simulate\n- **probs**: List of matrices containing class-conditional response probabilities (from a fitted model's `$probs`)\n- **P**: Vector of class mixing proportions (from a fitted model's `$P`)\n\nThe function returns a list including `$dat` (the simulated data frame) and `$trueclass` (true class memberships). See `?poLCA.simdata` for full documentation.\n:::\n\n### Iterative BLRT Comparison (Advanced)\n\nFor advanced users who want to automate the BLRT comparison across multiple class solutions, the following function iteratively runs the optimized BLRT for all comparisons up to a specified maximum number of classes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set the eval statement above to false to skip this chunk\n\n# Function to run optimized BLRT for all class comparisons up to max_classes\n# Returns a summary table similar to the original BLRT results\nrun_blrt_sequence <- function(formula, data, max_classes = 4, n_boot = 100, seed = 42) {\n\n  if (max_classes < 2) {\n    stop(\"max_classes must be at least 2\")\n  }\n\n  cat(sprintf(\"Running BLRT sequence for 2 to %d classes (%d bootstrap samples each)...\\n\\n\",\n              max_classes, n_boot))\n\n\n  # Store results\n  results_list <- list()\n\n  for (k in 2:max_classes) {\n    cat(sprintf(\"  Testing %d vs %d classes... \", k, k - 1))\n\n    # Run the optimized BLRT\n    blrt_result <- blrt_test_optimized(formula, data, k = k,\n                                        n_boot = n_boot, seed = seed + k)\n\n    # Store results\n    results_list[[k - 1]] <- data.frame(\n      Comparison = sprintf(\"%d vs %d Classes\", k, k - 1),\n      LRT_Statistic = blrt_result$lrt_statistic,\n      p_value = blrt_result$p_value,\n      N_Bootstrap = blrt_result$n_valid_boot,\n      Significant = ifelse(blrt_result$p_value < 0.05, \"Yes\", \"No\")\n    )\n\n    cat(sprintf(\"LRT = %.2f, p = %.4f %s\\n\",\n                blrt_result$lrt_statistic,\n                blrt_result$p_value,\n                ifelse(blrt_result$p_value < 0.05, \"*\", \"\")))\n  }\n\n  # Combine into single data frame\n  results_df <- do.call(rbind, results_list)\n  rownames(results_df) <- NULL\n\n  cat(\"\\n\")\n\n  return(results_df)\n}\n\n# Example: Run BLRT sequence comparing up to 4 classes\n# This will test: 2 vs 1, 3 vs 2, and 4 vs 3\nblrt_sequence_results <- run_blrt_sequence(\n  formula = lca_formula,\n  data = student_data,\n  max_classes = 4,\n  n_boot = 100\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRunning BLRT sequence for 2 to 4 classes (100 bootstrap samples each)...\n\n  Testing 2 vs 1 classes... \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLRT = 54.82, p = 0.0000 *\n  Testing 3 vs 2 classes... LRT = 7.58, p = 0.0800 \n  Testing 4 vs 3 classes... LRT = 0.18, p = 0.9000 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Display results table\nblrt_sequence_results %>%\n  kable(digits = 4, caption = \"Optimized BLRT Sequence Results\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\")) %>%\n  row_spec(which(blrt_sequence_results$Significant == \"Yes\"),\n           bold = TRUE, background = \"#d4edda\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Optimized BLRT Sequence Results</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Comparison </th>\n   <th style=\"text-align:right;\"> LRT_Statistic </th>\n   <th style=\"text-align:right;\"> p_value </th>\n   <th style=\"text-align:right;\"> N_Bootstrap </th>\n   <th style=\"text-align:left;\"> Significant </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;background-color: rgba(212, 237, 218, 255) !important;\"> 2 vs 1 Classes </td>\n   <td style=\"text-align:right;font-weight: bold;background-color: rgba(212, 237, 218, 255) !important;\"> 54.8222 </td>\n   <td style=\"text-align:right;font-weight: bold;background-color: rgba(212, 237, 218, 255) !important;\"> 0.00 </td>\n   <td style=\"text-align:right;font-weight: bold;background-color: rgba(212, 237, 218, 255) !important;\"> 100 </td>\n   <td style=\"text-align:left;font-weight: bold;background-color: rgba(212, 237, 218, 255) !important;\"> Yes </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 3 vs 2 Classes </td>\n   <td style=\"text-align:right;\"> 7.5820 </td>\n   <td style=\"text-align:right;\"> 0.08 </td>\n   <td style=\"text-align:right;\"> 100 </td>\n   <td style=\"text-align:left;\"> No </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 4 vs 3 Classes </td>\n   <td style=\"text-align:right;\"> 0.1793 </td>\n   <td style=\"text-align:right;\"> 0.90 </td>\n   <td style=\"text-align:right;\"> 100 </td>\n   <td style=\"text-align:left;\"> No </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n::: {.callout-note}\n## Using the Iterative BLRT Function\n\n**Parameters:**\n\n- `formula`: The LCA formula (e.g., `cbind(VAR1, VAR2, VAR3) ~ 1`)\n- `data`: Your data frame\n- `max_classes`: Maximum number of classes to test (default: 4)\n- `n_boot`: Number of bootstrap samples per comparison (default: 100; use 500+ for publication)\n- `seed`: Random seed for reproducibility\n\n**Output:**\n\nThe function returns a data frame with columns for Comparison, LRT_Statistic, p_value, N_Bootstrap, and Significant (Yes/No based on p < 0.05). Rows with significant p-values are highlighted in green.\n\n**Interpretation:**\n\n- Start from the top (2 vs 1) and move down\n- Stop at the first non-significant comparison\n- The simpler model in that comparison is your optimal solution\n- Example: If 2 vs 1 is significant but 3 vs 2 is not, select the 2-class model\n:::\n\n### Combined Fit Statistics Table\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create comprehensive fit statistics table\nfit_summary <- data.frame(\n  Model = names(models),\n  LogLik = sapply(models, function(m) m$llik),\n  AIC = sapply(models, function(m) m$aic),\n  BIC = sapply(models, function(m) m$bic),\n  Entropy = entropy_values,\n  AvePP = sapply(avepp_results, function(x) x$overall),\n  Min_OCC = sapply(occ_results, function(x) x$minimum)\n)\n\nfit_summary %>%\n  kable(digits = 3, caption = \"Comprehensive Fit Statistics Summary\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\")) %>%\n  row_spec(which.min(fit_summary$BIC), bold = TRUE, background = \"#e6f3ff\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Comprehensive Fit Statistics Summary</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">  </th>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:right;\"> LogLik </th>\n   <th style=\"text-align:right;\"> AIC </th>\n   <th style=\"text-align:right;\"> BIC </th>\n   <th style=\"text-align:right;\"> Entropy </th>\n   <th style=\"text-align:right;\"> AvePP </th>\n   <th style=\"text-align:right;\"> Min_OCC </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 1-Class </td>\n   <td style=\"text-align:left;\"> 1-Class </td>\n   <td style=\"text-align:right;\"> -467.438 </td>\n   <td style=\"text-align:right;\"> 942.876 </td>\n   <td style=\"text-align:right;\"> 957.937 </td>\n   <td style=\"text-align:right;\"> 1.000 </td>\n   <td style=\"text-align:right;\"> 1.000 </td>\n   <td style=\"text-align:right;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;background-color: rgba(230, 243, 255, 255) !important;\"> 2-Class </td>\n   <td style=\"text-align:left;font-weight: bold;background-color: rgba(230, 243, 255, 255) !important;\"> 2-Class </td>\n   <td style=\"text-align:right;font-weight: bold;background-color: rgba(230, 243, 255, 255) !important;\"> -440.027 </td>\n   <td style=\"text-align:right;font-weight: bold;background-color: rgba(230, 243, 255, 255) !important;\"> 898.054 </td>\n   <td style=\"text-align:right;font-weight: bold;background-color: rgba(230, 243, 255, 255) !important;\"> 931.941 </td>\n   <td style=\"text-align:right;font-weight: bold;background-color: rgba(230, 243, 255, 255) !important;\"> 0.737 </td>\n   <td style=\"text-align:right;font-weight: bold;background-color: rgba(230, 243, 255, 255) !important;\"> 0.870 </td>\n   <td style=\"text-align:right;font-weight: bold;background-color: rgba(230, 243, 255, 255) !important;\"> 5.233 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 3-Class </td>\n   <td style=\"text-align:left;\"> 3-Class </td>\n   <td style=\"text-align:right;\"> -436.236 </td>\n   <td style=\"text-align:right;\"> 900.472 </td>\n   <td style=\"text-align:right;\"> 953.184 </td>\n   <td style=\"text-align:right;\"> 0.889 </td>\n   <td style=\"text-align:right;\"> 0.887 </td>\n   <td style=\"text-align:right;\"> 4.296 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 4-Class </td>\n   <td style=\"text-align:left;\"> 4-Class </td>\n   <td style=\"text-align:right;\"> -436.145 </td>\n   <td style=\"text-align:right;\"> 910.291 </td>\n   <td style=\"text-align:right;\"> 981.829 </td>\n   <td style=\"text-align:right;\"> 0.620 </td>\n   <td style=\"text-align:right;\"> 0.775 </td>\n   <td style=\"text-align:right;\"> 2.141 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n**Note:** The highlighted row indicates the model with the lowest BIC.\n\n## Model Selection\n\nBased on the fit statistics above, we need to consider:\n\n1. **Information Criteria (AIC/BIC):** Lower values indicate better fit, with BIC generally preferred for class enumeration as it penalizes model complexity more heavily.\n\n2. **Entropy:** Values above 0.80 indicate good classification accuracy.\n\n3. **AvePP:** Values above 0.70 are acceptable; above 0.80 is good.\n\n4. **OCC:** Values above 5 indicate good class separation.\n\n5. **BLRT:** Significant p-values suggest the more complex model fits better.\n\n6. **Interpretability:** The solution should make theoretical sense.\n\n::: {.callout-important}\n## Interpreting the 1-Class Model\n\nThe **1-class model serves as a baseline** that assumes no latent heterogeneity - everyone comes from the same population with the same response probabilities.\n\n- **Entropy = 1.0 and AvePP = 1.0** for the 1-class model are **trivial/uninformative** - they simply mean everyone is assigned to the same class with certainty.\n- **OCC is not applicable** (NA) for the 1-class model since there's no classification decision to evaluate.\n- The key comparison is the **BLRT for 2 vs 1 classes** - a significant p-value demonstrates that the 2-class model is a significant improvement over the 1-class model, confirming that latent class structure exists in the data.\n\nIf the 2 vs 1 class BLRT is significant, this confirms that there are meaningful subgroups in the data that differ in their response patterns.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visual comparison of fit indices - 4 panel figure\n# Each statistic gets its own panel with appropriate scale\n\n# Create individual plots for each metric\np_bic <- ggplot(fit_summary, aes(x = Model, y = BIC, fill = Model)) +\n  geom_bar(stat = \"identity\") +\n  geom_text(aes(label = round(BIC, 1)), vjust = -0.5, size = 3) +\n  labs(title = \"BIC (lower is better)\", y = \"BIC\", x = \"\") +\n  theme_minimal() +\n  scale_fill_brewer(palette = \"Set2\") +\n  theme(legend.position = \"none\") +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.15)))\n\np_entropy <- ggplot(fit_summary, aes(x = Model, y = Entropy, fill = Model)) +\n  geom_bar(stat = \"identity\") +\n  geom_text(aes(label = round(Entropy, 3)), vjust = -0.5, size = 3) +\n  labs(title = \"Entropy (higher is better)\", y = \"Entropy\", x = \"\") +\n  theme_minimal() +\n  scale_fill_brewer(palette = \"Set2\") +\n  theme(legend.position = \"none\") +\n  scale_y_continuous(limits = c(0, 1), expand = expansion(mult = c(0, 0.1)))\n\np_avepp <- ggplot(fit_summary, aes(x = Model, y = AvePP, fill = Model)) +\n  geom_bar(stat = \"identity\") +\n  geom_text(aes(label = round(AvePP, 3)), vjust = -0.5, size = 3) +\n  labs(title = \"AvePP (higher is better)\", y = \"AvePP\", x = \"\") +\n  theme_minimal() +\n  scale_fill_brewer(palette = \"Set2\") +\n  theme(legend.position = \"none\") +\n  scale_y_continuous(limits = c(0, 1), expand = expansion(mult = c(0, 0.1)))\n\n# For OCC plot, filter out 1-class model (OCC is NA/not meaningful)\nfit_summary_occ <- fit_summary %>%\n  filter(!is.na(Min_OCC))\n\np_occ <- ggplot(fit_summary_occ, aes(x = Model, y = Min_OCC, fill = Model)) +\n  geom_bar(stat = \"identity\") +\n  geom_text(aes(label = round(Min_OCC, 2)), vjust = -0.5, size = 3) +\n  labs(title = \"Min OCC (higher is better)\", subtitle = \"(1-Class: N/A)\",\n       y = \"Min OCC\", x = \"\") +\n  theme_minimal() +\n  scale_fill_brewer(palette = \"Set2\") +\n  theme(legend.position = \"none\") +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.15)))\n\n# Combine into 2x2 grid using patchwork\n(p_bic | p_entropy) / (p_avepp | p_occ) +\n  plot_annotation(title = \"Fit Indices Comparison Across Models\")\n```\n\n::: {.cell-output-display}\n![](lca-walkthrough_files/figure-html/model-selection-1.png){width=864}\n:::\n:::\n\n\n## Interpreting the Selected Model\n\nFor this tutorial, let's examine the **2-class model** in detail (this is typically the best-fitting model for the cheating data based on BIC).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Select the best model (adjust based on your analysis)\nbest_model <- model_2\nn_classes <- 2\n\ncat(\"Selected Model:\", n_classes, \"Classes\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSelected Model: 2 Classes\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Log-likelihood:\", best_model$llik, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLog-likelihood: -440.0271 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"BIC:\", best_model$bic, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nBIC: 931.9409 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Entropy:\", round(calculate_entropy(best_model), 3), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEntropy: 0.737 \n```\n\n\n:::\n:::\n\n\n### Class Proportions\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Class proportions (prior probabilities)\nclass_props <- data.frame(\n  Class = paste(\"Class\", 1:n_classes),\n  Proportion = best_model$P,\n  Percentage = paste0(round(best_model$P * 100, 1), \"%\"),\n  N_estimated = round(best_model$P * nrow(student_data))\n)\n\nclass_props %>%\n  kable(caption = \"Class Proportions\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Class Proportions</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Class </th>\n   <th style=\"text-align:right;\"> Proportion </th>\n   <th style=\"text-align:left;\"> Percentage </th>\n   <th style=\"text-align:right;\"> N_estimated </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Class 1 </td>\n   <td style=\"text-align:right;\"> 0.8394377 </td>\n   <td style=\"text-align:left;\"> 83.9% </td>\n   <td style=\"text-align:right;\"> 268 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Class 2 </td>\n   <td style=\"text-align:right;\"> 0.1605623 </td>\n   <td style=\"text-align:left;\"> 16.1% </td>\n   <td style=\"text-align:right;\"> 51 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n### Item-Response Probabilities\n\nThe item-response probabilities show the probability of each response category for each indicator, conditional on class membership. This is the key output for interpreting what each class represents.\n\nFor binary indicators, we focus on the probability of \"Yes\" (category 2) for each behavior.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Extract and format item-response probabilities\nformat_probs <- function(model) {\n  probs_list <- model$probs\n\n  # Create a data frame for each variable\n  all_probs <- lapply(names(probs_list), function(var_name) {\n    probs_matrix <- probs_list[[var_name]]\n\n    df <- as.data.frame(probs_matrix)\n    colnames(df) <- c(\"No\", \"Yes\")  # Categories 1 and 2\n    df$Class <- paste(\"Class\", 1:nrow(df))\n    df$Variable <- var_name\n\n    df %>%\n      pivot_longer(cols = c(\"No\", \"Yes\"),\n                   names_to = \"Response\",\n                   values_to = \"Probability\")\n  })\n\n  bind_rows(all_probs)\n}\n\nitem_probs <- format_probs(best_model)\n\n# Display probability of \"Yes\" for each variable by class\nitem_probs %>%\n  filter(Response == \"Yes\") %>%\n  select(Variable, Class, Probability) %>%\n  pivot_wider(names_from = Class, values_from = Probability) %>%\n  kable(digits = 3,\n        caption = \"Probability of 'Yes' Response by Class\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Probability of 'Yes' Response by Class</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Variable </th>\n   <th style=\"text-align:right;\"> Class 1 </th>\n   <th style=\"text-align:right;\"> Class 2 </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> LIEEXAM </td>\n   <td style=\"text-align:right;\"> 0.017 </td>\n   <td style=\"text-align:right;\"> 0.577 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> LIEPAPER </td>\n   <td style=\"text-align:right;\"> 0.029 </td>\n   <td style=\"text-align:right;\"> 0.589 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> FRAUD </td>\n   <td style=\"text-align:right;\"> 0.037 </td>\n   <td style=\"text-align:right;\"> 0.216 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> COPYEXAM </td>\n   <td style=\"text-align:right;\"> 0.182 </td>\n   <td style=\"text-align:right;\"> 0.376 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n### Visualizing Class Profiles\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create profile plot showing probability of \"Yes\" for each behavior by class\nyes_probs <- item_probs %>%\n  filter(Response == \"Yes\") %>%\n  mutate(\n    Class = factor(Class),\n    Variable = factor(Variable,\n                      levels = c(\"LIEEXAM\", \"LIEPAPER\", \"FRAUD\", \"COPYEXAM\"),\n                      labels = c(\"Lied about\\nExam\", \"Lied about\\nPaper\",\n                                \"Bought\\nPaper\", \"Copied on\\nExam\"))\n  )\n\nggplot(yes_probs, aes(x = Variable, y = Probability,\n                       fill = Class, group = Class)) +\n  geom_bar(stat = \"identity\", position = \"dodge\", width = 0.7) +\n  geom_text(aes(label = sprintf(\"%.2f\", Probability)),\n            position = position_dodge(width = 0.7),\n            vjust = -0.5, size = 3) +\n  labs(title = \"Class Profiles: Probability of Each Cheating Behavior\",\n       subtitle = \"Item-response probabilities by latent class\",\n       y = \"Probability of 'Yes'\",\n       x = \"Cheating Behavior\") +\n  theme_minimal() +\n  scale_fill_brewer(palette = \"Set1\") +\n  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.2)) +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](lca-walkthrough_files/figure-html/class-profiles-1.png){width=864}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Alternative visualization: Line plot\nggplot(yes_probs, aes(x = Variable, y = Probability,\n                       color = Class, group = Class)) +\n  geom_line(linewidth = 1.2) +\n  geom_point(size = 4) +\n  labs(title = \"Class Profiles: Probability of Each Cheating Behavior\",\n       subtitle = \"Higher values indicate greater likelihood of the behavior\",\n       y = \"Probability of 'Yes'\",\n       x = \"Cheating Behavior\") +\n  theme_minimal() +\n  scale_color_brewer(palette = \"Set1\") +\n  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.2)) +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](lca-walkthrough_files/figure-html/profile-line-plot-1.png){width=864}\n:::\n:::\n\n\n### Class Membership\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Add predicted class to the data\nstudent_data_with_class <- student_data %>%\n  mutate(\n    Predicted_Class = best_model$predclass,\n    Max_Posterior = apply(best_model$posterior, 1, max)\n  )\n\n# Summary of class assignments\nstudent_data_with_class %>%\n  group_by(Predicted_Class) %>%\n  summarize(\n    N = n(),\n    Mean_Max_Posterior = mean(Max_Posterior),\n    Min_Max_Posterior = min(Max_Posterior),\n    Max_Max_Posterior = max(Max_Posterior)\n  ) %>%\n  kable(digits = 3, caption = \"Class Assignment Summary\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Class Assignment Summary</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> Predicted_Class </th>\n   <th style=\"text-align:right;\"> N </th>\n   <th style=\"text-align:right;\"> Mean_Max_Posterior </th>\n   <th style=\"text-align:right;\"> Min_Max_Posterior </th>\n   <th style=\"text-align:right;\"> Max_Max_Posterior </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 265 </td>\n   <td style=\"text-align:right;\"> 0.965 </td>\n   <td style=\"text-align:right;\"> 0.704 </td>\n   <td style=\"text-align:right;\"> 0.979 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 54 </td>\n   <td style=\"text-align:right;\"> 0.775 </td>\n   <td style=\"text-align:right;\"> 0.507 </td>\n   <td style=\"text-align:right;\"> 0.999 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n### Classification Table (Posterior Probabilities)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Average posterior probabilities for each class\navg_posterior <- best_model$posterior %>%\n  as.data.frame() %>%\n  mutate(Assigned_Class = best_model$predclass) %>%\n  group_by(Assigned_Class) %>%\n  summarize(across(everything(), mean))\n\ncolnames(avg_posterior) <- c(\"Assigned_Class\",\n                              paste(\"Posterior_Class\", 1:n_classes))\n\navg_posterior %>%\n  kable(digits = 3,\n        caption = \"Average Posterior Probabilities by Assigned Class\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Average Posterior Probabilities by Assigned Class</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> Assigned_Class </th>\n   <th style=\"text-align:right;\"> Posterior_Class 1 </th>\n   <th style=\"text-align:right;\"> Posterior_Class 2 </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0.965 </td>\n   <td style=\"text-align:right;\"> 0.035 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 0.225 </td>\n   <td style=\"text-align:right;\"> 0.775 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n**Interpretation:** The diagonal values represent the AvePP for each class. Higher diagonal values (and lower off-diagonal values) indicate better classification certainty.\n\n## Interpreting Your Results\n\nBased on our analysis of the cheating data, we can characterize the latent classes:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create interpretation based on item-response probabilities\ninterpretation <- item_probs %>%\n  filter(Response == \"Yes\") %>%\n  group_by(Class) %>%\n  summarize(\n    Mean_Prob_Yes = mean(Probability),\n    .groups = \"drop\"\n  ) %>%\n  mutate(\n    Class_Size = paste0(round(best_model$P * 100, 1), \"%\"),\n    Interpretation = case_when(\n      Mean_Prob_Yes > 0.5 ~ \"High Cheating Propensity\",\n      Mean_Prob_Yes > 0.2 ~ \"Moderate Cheating Propensity\",\n      TRUE ~ \"Low Cheating Propensity\"\n    )\n  )\n\ninterpretation %>%\n  kable(digits = 3, caption = \"Class Interpretation Summary\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Class Interpretation Summary</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Class </th>\n   <th style=\"text-align:right;\"> Mean_Prob_Yes </th>\n   <th style=\"text-align:left;\"> Class_Size </th>\n   <th style=\"text-align:left;\"> Interpretation </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Class 1 </td>\n   <td style=\"text-align:right;\"> 0.066 </td>\n   <td style=\"text-align:left;\"> 83.9% </td>\n   <td style=\"text-align:left;\"> Low Cheating Propensity </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Class 2 </td>\n   <td style=\"text-align:right;\"> 0.440 </td>\n   <td style=\"text-align:left;\"> 16.1% </td>\n   <td style=\"text-align:left;\"> Moderate Cheating Propensity </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n### Substantive Interpretation\n\nBased on the item-response probabilities, we can describe our classes:\n\n\n```{.r .cell-code}\n# Generate interpretation text based on probabilities\nprobs_wide <- item_probs %>%\n  filter(Response == \"Yes\") %>%\n  select(Class, Variable, Probability) %>%\n  pivot_wider(names_from = Variable, values_from = Probability)\n\nfor (i in 1:n_classes) {\n  class_probs <- probs_wide[i, ]\n  class_size <- round(best_model$P[i] * 100, 1)\n\n  cat(sprintf(\"\\n**%s** (%.1f%% of sample):\\n\\n\", class_probs$Class, class_size))\n\n  cat(sprintf(\"- Probability of lying about exam: %.1f%%\\n\",\n              class_probs$LIEEXAM * 100))\n  cat(sprintf(\"- Probability of lying about paper: %.1f%%\\n\",\n              class_probs$LIEPAPER * 100))\n  cat(sprintf(\"- Probability of buying a paper: %.1f%%\\n\",\n              class_probs$FRAUD * 100))\n  cat(sprintf(\"- Probability of copying on exam: %.1f%%\\n\\n\",\n              class_probs$COPYEXAM * 100))\n}\n```\n\n\n**Class 1** (83.9% of sample):\n\n- Probability of lying about exam: 1.7%\n- Probability of lying about paper: 2.9%\n- Probability of buying a paper: 3.7%\n- Probability of copying on exam: 18.2%\n\n\n**Class 2** (16.1% of sample):\n\n- Probability of lying about exam: 57.7%\n- Probability of lying about paper: 58.9%\n- Probability of buying a paper: 21.6%\n- Probability of copying on exam: 37.6%\n\n## Adding Covariates to Predict Class Membership\n\nA common next step in LCA is to examine how demographic variables or other characteristics predict membership in the latent classes. Our synthetic demographic data includes **AGE**, **SCHOOL** level, and **GPA_ZSCORE** (standardized GPA within school level) as potential predictors.\n\n### Why Add Covariates?\n\nAdding covariates allows us to answer questions like:\n\n- Are older students more likely to belong to the \"cheating\" class?\n- Does cheating behavior differ across school levels (Elementary, Middle, High School)?\n- Are students with lower GPAs (relative to their peers) more likely to cheat?\n\nIn `poLCA`, covariates are added to the right side of the formula and affect the **probability of class membership** (not the item-response probabilities).\n\n### Preparing Covariates\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Check our demographic variables\nsummary(student_data[, c(\"AGE\", \"SCHOOL\", \"GPA_ZSCORE\")])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      AGE                 SCHOOL      GPA_ZSCORE     \n Min.   :10.0   Elementary   : 72   Min.   :-3.1160  \n 1st Qu.:13.0   Middle School:123   1st Qu.:-0.6695  \n Median :15.0   High School  :124   Median : 0.0330  \n Mean   :14.5                       Mean   : 0.0000  \n 3rd Qu.:16.0                       3rd Qu.: 0.7070  \n Max.   :18.0                       Max.   : 1.9440  \n```\n\n\n:::\n\n```{.r .cell-code}\n# For poLCA, we need to dummy-code categorical variables\n# Create dummy variables for SCHOOL (Elementary is reference category)\nstudent_data <- student_data %>%\n  mutate(\n    SCHOOL_Middle = ifelse(SCHOOL == \"Middle School\", 1, 0),\n    SCHOOL_High = ifelse(SCHOOL == \"High School\", 1, 0)\n  )\n\n# Verify the coding\ntable(student_data$SCHOOL, student_data$SCHOOL_Middle)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n               \n                  0   1\n  Elementary     72   0\n  Middle School   0 123\n  High School   124   0\n```\n\n\n:::\n\n```{.r .cell-code}\ntable(student_data$SCHOOL, student_data$SCHOOL_High)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n               \n                  0   1\n  Elementary     72   0\n  Middle School 123   0\n  High School     0 124\n```\n\n\n:::\n:::\n\n\n### Fit Model with Multiple Covariates\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define formula with AGE, SCHOOL dummies, and GPA_ZSCORE as covariates\n# Note: We use SCHOOL dummies rather than SCHOOL factor because poLCA\n# requires numeric covariates\nlca_formula_cov <- cbind(LIEEXAM, LIEPAPER, FRAUD, COPYEXAM) ~\n  AGE + SCHOOL_Middle + SCHOOL_High + GPA_ZSCORE\n\n# Fit the 2-class model with covariates\nset.seed(42)\nmodel_2_cov <- poLCA(lca_formula_cov, data = student_data, nclass = 2,\n                     nrep = 10, verbose = FALSE)\n```\n:::\n\n\n### Interpreting Covariate Effects\n\nThe covariate coefficients are interpreted similarly to logistic regression. They represent the effect of the covariate on the **log-odds** of being in class k versus the reference class (the last class).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Extract and display covariate coefficients\n# poLCA uses the last class as the reference category\ncoef_names <- c(\"Intercept\", \"AGE\", \"SCHOOL_Middle\", \"SCHOOL_High\", \"GPA_ZSCORE\")\n\ncoef_table <- data.frame(\n  Variable = coef_names,\n  Coefficient = as.numeric(model_2_cov$coeff),\n  SE = sqrt(diag(model_2_cov$coeff.V))\n)\n\n# Calculate z-values and p-values\ncoef_table$z_value <- coef_table$Coefficient / coef_table$SE\ncoef_table$p_value <- 2 * (1 - pnorm(abs(coef_table$z_value)))\n\n# Calculate odds ratios for easier interpretation\ncoef_table$Odds_Ratio <- exp(coef_table$Coefficient)\n\ncoef_table %>%\n  kable(digits = 3,\n        caption = \"Covariate Effects on Class Membership (Class 1 vs Class 2)\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Covariate Effects on Class Membership (Class 1 vs Class 2)</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Variable </th>\n   <th style=\"text-align:right;\"> Coefficient </th>\n   <th style=\"text-align:right;\"> SE </th>\n   <th style=\"text-align:right;\"> z_value </th>\n   <th style=\"text-align:right;\"> p_value </th>\n   <th style=\"text-align:right;\"> Odds_Ratio </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Intercept </td>\n   <td style=\"text-align:right;\"> 5.030 </td>\n   <td style=\"text-align:right;\"> 3.169 </td>\n   <td style=\"text-align:right;\"> 1.587 </td>\n   <td style=\"text-align:right;\"> 0.112 </td>\n   <td style=\"text-align:right;\"> 152.965 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> AGE </td>\n   <td style=\"text-align:right;\"> -0.305 </td>\n   <td style=\"text-align:right;\"> 0.263 </td>\n   <td style=\"text-align:right;\"> -1.160 </td>\n   <td style=\"text-align:right;\"> 0.246 </td>\n   <td style=\"text-align:right;\"> 0.737 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> SCHOOL_Middle </td>\n   <td style=\"text-align:right;\"> 1.364 </td>\n   <td style=\"text-align:right;\"> 0.923 </td>\n   <td style=\"text-align:right;\"> 1.478 </td>\n   <td style=\"text-align:right;\"> 0.139 </td>\n   <td style=\"text-align:right;\"> 3.913 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> SCHOOL_High </td>\n   <td style=\"text-align:right;\"> 1.617 </td>\n   <td style=\"text-align:right;\"> 1.515 </td>\n   <td style=\"text-align:right;\"> 1.067 </td>\n   <td style=\"text-align:right;\"> 0.286 </td>\n   <td style=\"text-align:right;\"> 5.038 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> GPA_ZSCORE </td>\n   <td style=\"text-align:right;\"> -0.221 </td>\n   <td style=\"text-align:right;\"> 0.208 </td>\n   <td style=\"text-align:right;\"> -1.065 </td>\n   <td style=\"text-align:right;\"> 0.287 </td>\n   <td style=\"text-align:right;\"> 0.801 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n### Interpretation\n\n\n```{.r .cell-code}\n# Determine which class is the \"cheating\" class based on item probabilities\nclass1_cheat_prob <- mean(sapply(model_2_cov$probs, function(x) x[1, 2]))\nclass2_cheat_prob <- mean(sapply(model_2_cov$probs, function(x) x[2, 2]))\n\nif (class1_cheat_prob > class2_cheat_prob) {\n  cheating_class <- 1\n  noncheating_class <- 2\n  comparison_text <- \"Class 1 (higher cheating) vs Class 2 (lower cheating)\"\n} else {\n  cheating_class <- 2\n  noncheating_class <- 1\n  comparison_text <- \"Class 1 (lower cheating) vs Class 2 (higher cheating)\"\n}\n\ncat(\"**Interpreting the coefficients** (\", comparison_text, \"):\\n\\n\", sep = \"\")\n```\n\n**Interpreting the coefficients** (Class 1 (higher cheating) vs Class 2 (lower cheating)):\n\n```{.r .cell-code}\n# AGE effect\nage_coef <- coef_table$Coefficient[coef_table$Variable == \"AGE\"]\nage_or <- coef_table$Odds_Ratio[coef_table$Variable == \"AGE\"]\nage_p <- coef_table$p_value[coef_table$Variable == \"AGE\"]\ncat(sprintf(\"- **AGE:** For each additional year of age, the odds of being in Class 1 (vs Class 2) change by a factor of %.3f (OR = %.3f, p = %.3f).\\n\\n\",\n            age_or, age_or, age_p))\n```\n\n- **AGE:** For each additional year of age, the odds of being in Class 1 (vs Class 2) change by a factor of 0.737 (OR = 0.737, p = 0.246).\n\n```{.r .cell-code}\n# School effects\nmiddle_or <- coef_table$Odds_Ratio[coef_table$Variable == \"SCHOOL_Middle\"]\nmiddle_p <- coef_table$p_value[coef_table$Variable == \"SCHOOL_Middle\"]\nhigh_or <- coef_table$Odds_Ratio[coef_table$Variable == \"SCHOOL_High\"]\nhigh_p <- coef_table$p_value[coef_table$Variable == \"SCHOOL_High\"]\n\ncat(sprintf(\"- **Middle School vs Elementary:** Students in Middle School have %.3f times the odds of being in Class 1 compared to Elementary students (p = %.3f).\\n\\n\",\n            middle_or, middle_p))\n```\n\n- **Middle School vs Elementary:** Students in Middle School have 3.913 times the odds of being in Class 1 compared to Elementary students (p = 0.139).\n\n```{.r .cell-code}\ncat(sprintf(\"- **High School vs Elementary:** Students in High School have %.3f times the odds of being in Class 1 compared to Elementary students (p = %.3f).\\n\\n\",\n            high_or, high_p))\n```\n\n- **High School vs Elementary:** Students in High School have 5.038 times the odds of being in Class 1 compared to Elementary students (p = 0.286).\n\n```{.r .cell-code}\n# GPA effect\ngpa_coef <- coef_table$Coefficient[coef_table$Variable == \"GPA_ZSCORE\"]\ngpa_or <- coef_table$Odds_Ratio[coef_table$Variable == \"GPA_ZSCORE\"]\ngpa_p <- coef_table$p_value[coef_table$Variable == \"GPA_ZSCORE\"]\ncat(sprintf(\"- **GPA_ZSCORE:** For each 1 standard deviation increase in GPA (relative to school-level peers), the odds of being in Class 1 change by a factor of %.3f (p = %.3f).\\n\\n\",\n            gpa_or, gpa_p))\n```\n\n- **GPA_ZSCORE:** For each 1 standard deviation increase in GPA (relative to school-level peers), the odds of being in Class 1 change by a factor of 0.801 (p = 0.287).\n\n### Visualizing Covariate Effects\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot 1: Predicted class membership by AGE (holding other vars at mean/reference)\nage_range <- 10:18\n\n# Calculate predicted probabilities across age range\n# Hold SCHOOL at reference (Elementary: both dummies = 0) and GPA_ZSCORE at 0\nlogit_class1_age <- model_2_cov$coeff[1] + model_2_cov$coeff[2] * age_range\nprob_class1_age <- exp(logit_class1_age) / (1 + exp(logit_class1_age))\n\nage_pred <- data.frame(\n  AGE = rep(age_range, 2),\n  Probability = c(prob_class1_age, 1 - prob_class1_age),\n  Class = factor(rep(c(\"Class 1\", \"Class 2\"), each = length(age_range)))\n)\n\np_age <- ggplot(age_pred, aes(x = AGE, y = Probability, color = Class)) +\n  geom_line(linewidth = 1.2) +\n  labs(title = \"Predicted Class Membership by Age\",\n       subtitle = \"Elementary students, average GPA\",\n       x = \"Age (years)\", y = \"Probability\") +\n  theme_minimal() +\n  scale_color_brewer(palette = \"Set1\") +\n  scale_x_continuous(breaks = 10:18) +\n  scale_y_continuous(limits = c(0, 1)) +\n  theme(legend.position = \"bottom\")\n\n# Plot 2: Predicted class membership by SCHOOL level\nschool_pred <- data.frame(\n  SCHOOL = factor(c(\"Elementary\", \"Middle School\", \"High School\"),\n                  levels = c(\"Elementary\", \"Middle School\", \"High School\"))\n)\n\n# Calculate predictions at mean age (14) and mean GPA_ZSCORE (0)\nmean_age <- 14\nschool_pred$SCHOOL_Middle <- c(0, 1, 0)\nschool_pred$SCHOOL_High <- c(0, 0, 1)\n\nlogit_school <- model_2_cov$coeff[1] +\n  model_2_cov$coeff[2] * mean_age +\n  model_2_cov$coeff[3] * school_pred$SCHOOL_Middle +\n  model_2_cov$coeff[4] * school_pred$SCHOOL_High\n\nschool_pred$Prob_Class1 <- exp(logit_school) / (1 + exp(logit_school))\nschool_pred$Prob_Class2 <- 1 - school_pred$Prob_Class1\n\nschool_long <- school_pred %>%\n  select(SCHOOL, Prob_Class1, Prob_Class2) %>%\n  pivot_longer(cols = starts_with(\"Prob\"),\n               names_to = \"Class\",\n               values_to = \"Probability\") %>%\n  mutate(Class = ifelse(Class == \"Prob_Class1\", \"Class 1\", \"Class 2\"))\n\np_school <- ggplot(school_long, aes(x = SCHOOL, y = Probability, fill = Class)) +\n  geom_col(position = \"dodge\", alpha = 0.8) +\n  labs(title = \"Predicted Class Membership by School Level\",\n       subtitle = \"Age 14, average GPA\",\n       x = \"\", y = \"Probability\") +\n  theme_minimal() +\n  scale_fill_brewer(palette = \"Set1\") +\n  scale_y_continuous(limits = c(0, 1)) +\n  theme(legend.position = \"bottom\")\n\np_age | p_school\n```\n\n::: {.cell-output-display}\n![](lca-walkthrough_files/figure-html/covariate-plot-age-1.png){width=960}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot: Predicted class membership by GPA_ZSCORE\ngpa_z_range <- seq(-2.5, 2.5, length.out = 100)\n\n# Calculate at mean age, Elementary school (reference)\nlogit_gpa <- model_2_cov$coeff[1] +\n  model_2_cov$coeff[2] * 14 +  # mean age\n  model_2_cov$coeff[5] * gpa_z_range\n\nprob_class1_gpa <- exp(logit_gpa) / (1 + exp(logit_gpa))\n\ngpa_pred <- data.frame(\n  GPA_ZSCORE = rep(gpa_z_range, 2),\n  Probability = c(prob_class1_gpa, 1 - prob_class1_gpa),\n  Class = factor(rep(c(\"Class 1\", \"Class 2\"), each = length(gpa_z_range)))\n)\n\nggplot(gpa_pred, aes(x = GPA_ZSCORE, y = Probability, color = Class)) +\n  geom_line(linewidth = 1.2) +\n  geom_vline(xintercept = 0, linetype = \"dashed\", alpha = 0.5) +\n  labs(title = \"Predicted Class Membership by Standardized GPA\",\n       subtitle = \"Age 14, Elementary school\",\n       x = \"GPA Z-Score (relative to school-level peers)\",\n       y = \"Probability of Class Membership\") +\n  theme_minimal() +\n  scale_color_brewer(palette = \"Set1\") +\n  scale_y_continuous(limits = c(0, 1)) +\n  annotate(\"text\", x = -1.5, y = 0.05, label = \"Below Average GPA\", size = 3) +\n  annotate(\"text\", x = 1.5, y = 0.05, label = \"Above Average GPA\", size = 3) +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](lca-walkthrough_files/figure-html/covariate-plot-gpa-1.png){width=768}\n:::\n:::\n\n\n### Comparing Models With and Without Covariates\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compare fit of models with and without covariates\ncomparison <- data.frame(\n  Model = c(\"Without Covariates\", \"With Covariates\"),\n  LogLik = c(model_2$llik, model_2_cov$llik),\n  AIC = c(model_2$aic, model_2_cov$aic),\n  BIC = c(model_2$bic, model_2_cov$bic),\n  N_parameters = c(model_2$npar, model_2_cov$npar)\n)\n\ncomparison %>%\n  kable(digits = 2, caption = \"Model Comparison: With vs. Without Covariates\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Model Comparison: With vs. Without Covariates</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:right;\"> LogLik </th>\n   <th style=\"text-align:right;\"> AIC </th>\n   <th style=\"text-align:right;\"> BIC </th>\n   <th style=\"text-align:right;\"> N_parameters </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Without Covariates </td>\n   <td style=\"text-align:right;\"> -440.03 </td>\n   <td style=\"text-align:right;\"> 898.05 </td>\n   <td style=\"text-align:right;\"> 931.94 </td>\n   <td style=\"text-align:right;\"> 9 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> With Covariates </td>\n   <td style=\"text-align:right;\"> -437.39 </td>\n   <td style=\"text-align:right;\"> 900.77 </td>\n   <td style=\"text-align:right;\"> 949.72 </td>\n   <td style=\"text-align:right;\"> 13 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n\n```{.r .cell-code}\n# Likelihood ratio test for nested models\nlr_stat <- 2 * (model_2_cov$llik - model_2$llik)\nlr_df <- model_2_cov$npar - model_2$npar\nlr_p <- 1 - pchisq(lr_stat, df = lr_df)\n\ncat(sprintf(\"\\nLikelihood Ratio Test: Ï‡Â² = %.3f, df = %d, p = %.4f\\n\",\n            lr_stat, lr_df, lr_p))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nLikelihood Ratio Test: Ï‡Â² = 5.281, df = 4, p = 0.2597\n```\n\n\n:::\n\n```{.r .cell-code}\nif (lr_p < 0.05) {\n  cat(\"\\nThe covariates significantly improve model fit.\\n\")\n} else {\n  cat(\"\\nThe covariates do not significantly improve model fit.\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nThe covariates do not significantly improve model fit.\n```\n\n\n:::\n:::\n\n\n::: {.callout-tip}\n## Understanding Covariate Effects in LCA\n\n**Key points about covariates in poLCA:**\n\n1. **Reference class:** poLCA uses the last class as the reference category. Coefficients represent log-odds of being in Class 1 vs Class 2.\n\n2. **Reference categories for categorical covariates:** Elementary school is our reference (both dummy variables = 0).\n\n3. **Standardized coefficients:** Using GPA_ZSCORE (z-scored within school level) allows for cleaner interpretation - a 1-unit change represents 1 standard deviation.\n\n4. **No effect on item probabilities:** Covariates in poLCA only affect class membership probabilities, not the item-response probabilities within classes.\n:::\n\n## SHAP Values for Predictor Importance (Optional)\n\n::: {.callout-note}\n## Advanced Topic\n\nThis section uses **SHAP (SHapley Additive exPlanations) values** to understand which predictors are most important for class membership. SHAP values come from machine learning interpretability research and provide a principled way to attribute predictions to individual features.\n\nThis approach is optional and more advanced than the standard covariate analysis above.\n:::\n\n### What are SHAP Values?\n\nSHAP values decompose a prediction into the contribution of each feature. For our LCA covariate model, SHAP values help answer: \"How much does each predictor (AGE, SCHOOL, GPA_ZSCORE) contribute to an individual's predicted class membership?\"\n\nKey advantages:\n- **Local interpretability:** Understand predictions for individual students\n- **Global interpretability:** Aggregate to see overall feature importance\n- **Accounts for interactions:** Unlike simple coefficient interpretation\n\n### Computing SHAP Values\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load additional packages for SHAP analysis\nlibrary(randomForest)\nlibrary(fastshap)\n\n# Prepare data for SHAP analysis\n# We'll use the posterior probability of Class 1 as our outcome\nstudent_data$Prob_Class1 <- best_model$posterior[, 1]\n\n# Select predictors\npredictors <- c(\"AGE\", \"SCHOOL_Middle\", \"SCHOOL_High\", \"GPA_ZSCORE\")\nX <- student_data[, predictors]\n\n# Create a prediction wrapper function\n# This function takes new data and returns predicted probabilities\npredict_fn <- function(object, newdata) {\n  # Use the covariate model coefficients to predict\n  logit <- model_2_cov$coeff[1] +\n    model_2_cov$coeff[2] * newdata$AGE +\n    model_2_cov$coeff[3] * newdata$SCHOOL_Middle +\n    model_2_cov$coeff[4] * newdata$SCHOOL_High +\n    model_2_cov$coeff[5] * newdata$GPA_ZSCORE\n  exp(logit) / (1 + exp(logit))\n}\n\n# Compute SHAP values\nset.seed(42)\nshap_values <- explain(\n  object = NULL,  # We're using our custom predict function\n  X = X,\n  pred_wrapper = function(model, newdata) predict_fn(NULL, newdata),\n  nsim = 50  # Number of Monte Carlo simulations\n)\n\n# Convert to data frame\nshap_df <- as.data.frame(shap_values)\ncolnames(shap_df) <- predictors\n```\n:::\n\n\n### Global Feature Importance\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate mean absolute SHAP values for global importance\nimportance_df <- data.frame(\n  Variable = predictors,\n  Mean_Abs_SHAP = colMeans(abs(shap_df))\n) %>%\n  mutate(\n    Variable = factor(Variable, levels = Variable[order(Mean_Abs_SHAP)])\n  )\n\nggplot(importance_df, aes(x = Mean_Abs_SHAP, y = Variable)) +\n  geom_col(fill = \"steelblue\", alpha = 0.8) +\n  labs(title = \"Global Feature Importance (SHAP Values)\",\n       subtitle = \"Mean |SHAP value| across all students\",\n       x = \"Mean Absolute SHAP Value\",\n       y = \"\") +\n  theme_minimal() +\n  theme(axis.text.y = element_text(size = 11))\n```\n\n::: {.cell-output-display}\n![](lca-walkthrough_files/figure-html/shap-importance-1.png){width=768}\n:::\n:::\n\n\n### SHAP Summary Plot\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create a summary plot showing SHAP values by feature value\nshap_long <- shap_df %>%\n  mutate(row_id = row_number()) %>%\n  pivot_longer(cols = -row_id, names_to = \"Variable\", values_to = \"SHAP\") %>%\n  left_join(\n    X %>%\n      mutate(row_id = row_number()) %>%\n      pivot_longer(cols = -row_id, names_to = \"Variable\", values_to = \"Feature_Value\"),\n    by = c(\"row_id\", \"Variable\")\n  )\n\n# Scale feature values to 0-1 for coloring\nshap_long <- shap_long %>%\n  group_by(Variable) %>%\n  mutate(Feature_Scaled = (Feature_Value - min(Feature_Value)) /\n           (max(Feature_Value) - min(Feature_Value) + 0.001)) %>%\n  ungroup()\n\n# Order variables by importance\nvar_order <- importance_df %>%\n  arrange(desc(Mean_Abs_SHAP)) %>%\n  pull(Variable) %>%\n  as.character()\n\nshap_long$Variable <- factor(shap_long$Variable, levels = rev(var_order))\n\nggplot(shap_long, aes(x = SHAP, y = Variable, color = Feature_Scaled)) +\n  geom_jitter(alpha = 0.6, height = 0.2, size = 1.5) +\n  scale_color_gradient2(low = \"blue\", mid = \"gray80\", high = \"red\",\n                        midpoint = 0.5,\n                        name = \"Feature Value\\n(Normalized)\") +\n  geom_vline(xintercept = 0, linetype = \"dashed\", alpha = 0.5) +\n  labs(title = \"SHAP Summary Plot\",\n       subtitle = \"How feature values affect Class 1 membership probability\",\n       x = \"SHAP Value (impact on Class 1 probability)\",\n       y = \"\") +\n  theme_minimal() +\n  theme(legend.position = \"right\",\n        axis.text.y = element_text(size = 11))\n```\n\n::: {.cell-output-display}\n![](lca-walkthrough_files/figure-html/shap-summary-1.png){width=960}\n:::\n:::\n\n\n### Interpreting SHAP Values\n\n\n```{.r .cell-code}\ncat(\"**How to read the SHAP summary plot:**\\n\\n\")\n```\n\n**How to read the SHAP summary plot:**\n\n```{.r .cell-code}\ncat(\"- Each dot represents one student\\n\")\n```\n\n- Each dot represents one student\n\n```{.r .cell-code}\ncat(\"- **Horizontal position:** SHAP value (how much this feature pushes prediction toward Class 1)\\n\")\n```\n\n- **Horizontal position:** SHAP value (how much this feature pushes prediction toward Class 1)\n\n```{.r .cell-code}\ncat(\"- **Color:** Feature value (red = high, blue = low)\\n\")\n```\n\n- **Color:** Feature value (red = high, blue = low)\n\n```{.r .cell-code}\ncat(\"- **Vertical spread:** Shows distribution of SHAP values for that feature\\n\\n\")\n```\n\n- **Vertical spread:** Shows distribution of SHAP values for that feature\n\n```{.r .cell-code}\ncat(\"**Example interpretations:**\\n\\n\")\n```\n\n**Example interpretations:**\n\n```{.r .cell-code}\ncat(\"- If AGE shows red dots on the right: older students are pushed toward Class 1\\n\")\n```\n\n- If AGE shows red dots on the right: older students are pushed toward Class 1\n\n```{.r .cell-code}\ncat(\"- If GPA_ZSCORE shows blue dots on the right: lower GPA pushes toward Class 1\\n\")\n```\n\n- If GPA_ZSCORE shows blue dots on the right: lower GPA pushes toward Class 1\n\n```{.r .cell-code}\ncat(\"- Features with wider horizontal spread have more variable effects\\n\")\n```\n\n- Features with wider horizontal spread have more variable effects\n\n### Individual Student SHAP Breakdown\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Show SHAP breakdown for a few example students\nexample_students <- c(1, 50, 100)\n\nindividual_shap <- shap_df[example_students, ] %>%\n  mutate(Student = paste(\"Student\", example_students)) %>%\n  pivot_longer(cols = -Student, names_to = \"Variable\", values_to = \"SHAP\")\n\n# Add student characteristics\nstudent_chars <- student_data[example_students, c(\"AGE\", \"SCHOOL\", \"GPA_ZSCORE\", \"Prob_Class1\")]\nstudent_chars$Student <- paste(\"Student\", example_students)\n\nindividual_shap <- individual_shap %>%\n  left_join(student_chars %>% select(Student, Prob_Class1), by = \"Student\")\n\nggplot(individual_shap, aes(x = SHAP, y = Variable, fill = SHAP > 0)) +\n  geom_col(alpha = 0.8, show.legend = FALSE) +\n  facet_wrap(~Student, scales = \"free_x\") +\n  scale_fill_manual(values = c(\"steelblue\", \"coral\")) +\n  geom_vline(xintercept = 0, linetype = \"dashed\") +\n  labs(title = \"Individual SHAP Value Breakdown\",\n       subtitle = \"Feature contributions to Class 1 probability for example students\",\n       x = \"SHAP Value\", y = \"\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](lca-walkthrough_files/figure-html/shap-individual-1.png){width=960}\n:::\n\n```{.r .cell-code}\n# Print characteristics\ncat(\"\\n**Example student characteristics:**\\n\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n**Example student characteristics:**\n```\n\n\n:::\n\n```{.r .cell-code}\nstudent_chars %>%\n  kable(digits = 2, caption = \"Characteristics of Example Students\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Characteristics of Example Students</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">  </th>\n   <th style=\"text-align:right;\"> AGE </th>\n   <th style=\"text-align:left;\"> SCHOOL </th>\n   <th style=\"text-align:right;\"> GPA_ZSCORE </th>\n   <th style=\"text-align:right;\"> Prob_Class1 </th>\n   <th style=\"text-align:left;\"> Student </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:right;\"> 18 </td>\n   <td style=\"text-align:left;\"> High School </td>\n   <td style=\"text-align:right;\"> 0.70 </td>\n   <td style=\"text-align:right;\"> 0.98 </td>\n   <td style=\"text-align:left;\"> Student 1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 50 </td>\n   <td style=\"text-align:right;\"> 11 </td>\n   <td style=\"text-align:left;\"> Elementary </td>\n   <td style=\"text-align:right;\"> 1.76 </td>\n   <td style=\"text-align:right;\"> 0.98 </td>\n   <td style=\"text-align:left;\"> Student 50 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 100 </td>\n   <td style=\"text-align:right;\"> 15 </td>\n   <td style=\"text-align:left;\"> Middle School </td>\n   <td style=\"text-align:right;\"> 1.85 </td>\n   <td style=\"text-align:right;\"> 0.98 </td>\n   <td style=\"text-align:left;\"> Student 100 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n::: {.callout-tip}\n## When to Use SHAP Values\n\nSHAP values are most useful when:\n\n1. **You have many predictors** and want to rank their importance\n2. **You want individual-level explanations** for specific predictions\n3. **You suspect non-linear effects** or interactions between predictors\n4. **Communicating results** to audiences familiar with machine learning interpretability\n\nFor simpler models with few predictors, the standard coefficient interpretation may be sufficient.\n:::\n\n## Exporting Results\n\n### Save Class Assignments\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create output dataset with class assignments and posteriors\noutput_data <- student_data %>%\n  mutate(\n    Predicted_Class = best_model$predclass,\n    Posterior_Class1 = best_model$posterior[, 1],\n    Posterior_Class2 = best_model$posterior[, 2]\n  )\n\n# Save to CSV (uncomment to save)\n# write_csv(output_data, \"lca_results.csv\")\n\n# Display first few rows\nhead(output_data) %>%\n  select(AGE, SCHOOL, GPA, GPA_ZSCORE, LIEEXAM:COPYEXAM,\n         Predicted_Class, Posterior_Class1, Posterior_Class2) %>%\n  kable(digits = 3, caption = \"Output Data with Class Assignments\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Output Data with Class Assignments</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> AGE </th>\n   <th style=\"text-align:left;\"> SCHOOL </th>\n   <th style=\"text-align:right;\"> GPA </th>\n   <th style=\"text-align:right;\"> GPA_ZSCORE </th>\n   <th style=\"text-align:right;\"> LIEEXAM </th>\n   <th style=\"text-align:right;\"> LIEPAPER </th>\n   <th style=\"text-align:right;\"> FRAUD </th>\n   <th style=\"text-align:right;\"> COPYEXAM </th>\n   <th style=\"text-align:right;\"> Predicted_Class </th>\n   <th style=\"text-align:right;\"> Posterior_Class1 </th>\n   <th style=\"text-align:right;\"> Posterior_Class2 </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 18 </td>\n   <td style=\"text-align:left;\"> High School </td>\n   <td style=\"text-align:right;\"> 3.13 </td>\n   <td style=\"text-align:right;\"> 0.704 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0.979 </td>\n   <td style=\"text-align:right;\"> 0.021 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 12 </td>\n   <td style=\"text-align:left;\"> Elementary </td>\n   <td style=\"text-align:right;\"> 2.47 </td>\n   <td style=\"text-align:right;\"> -1.884 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0.979 </td>\n   <td style=\"text-align:right;\"> 0.021 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 15 </td>\n   <td style=\"text-align:left;\"> Middle School </td>\n   <td style=\"text-align:right;\"> 3.48 </td>\n   <td style=\"text-align:right;\"> 1.071 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0.979 </td>\n   <td style=\"text-align:right;\"> 0.021 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 11 </td>\n   <td style=\"text-align:left;\"> Elementary </td>\n   <td style=\"text-align:right;\"> 3.34 </td>\n   <td style=\"text-align:right;\"> 0.200 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0.979 </td>\n   <td style=\"text-align:right;\"> 0.021 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 10 </td>\n   <td style=\"text-align:left;\"> Elementary </td>\n   <td style=\"text-align:right;\"> 2.90 </td>\n   <td style=\"text-align:right;\"> -0.863 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0.979 </td>\n   <td style=\"text-align:right;\"> 0.021 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 17 </td>\n   <td style=\"text-align:left;\"> High School </td>\n   <td style=\"text-align:right;\"> 1.91 </td>\n   <td style=\"text-align:right;\"> -0.826 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0.979 </td>\n   <td style=\"text-align:right;\"> 0.021 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n## Summary\n\nIn this tutorial, we covered:\n\n1. **Setting up LCA** using the `poLCA` package in R\n2. **Creating synthetic demographic data** with realistic school-clustered distributions\n3. **Fitting models** with different numbers of classes\n4. **Calculating fit statistics:**\n   - Basic: AIC, BIC, Log-likelihood\n   - Classification quality: Entropy, AvePP, OCC\n   - Model comparison: Bootstrap LRT\n5. **Selecting the optimal model** based on multiple criteria\n6. **Interpreting results** through item-response probabilities and class profiles\n7. **Adding covariates** (AGE, SCHOOL, GPA_ZSCORE) to predict class membership\n8. **Using SHAP values** (optional) to understand predictor importance and individual-level explanations\n\n### Key Takeaways\n\n- **Always compare multiple models** with different numbers of classes\n- **Use multiple fit indices** - no single statistic should determine model selection\n- **Consider interpretability** - the solution should make theoretical sense\n- **Report classification quality** - entropy, AvePP, and OCC indicate how well individuals are classified\n- **Use sufficient starting values** (nrep) to avoid local maxima\n- **Z-score continuous covariates** within meaningful groups for cleaner interpretation\n- **SHAP values** provide a powerful complement to coefficient-based interpretation\n\n## References\n\n- Linzer, D. A., & Lewis, J. B. (2011). poLCA: An R package for polytomous variable latent class analysis. *Journal of Statistical Software, 42*(10), 1-29.\n- Nylund, K. L., Asparouhov, T., & Muthen, B. O. (2007). Deciding on the number of classes in latent class analysis and growth mixture modeling: A Monte Carlo simulation study. *Structural Equation Modeling, 14*(4), 535-569.\n- Collins, L. M., & Lanza, S. T. (2010). *Latent class and latent transition analysis: With applications in the social, behavioral, and health sciences*. John Wiley & Sons.\n\n## Session Info\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nR version 4.5.2 (2025-10-31)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Tahoe 26.2\n\nMatrix products: default\nBLAS:   /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n\nlocale:\n[1] C.UTF-8/C.UTF-8/C.UTF-8/C/C.UTF-8/C.UTF-8\n\ntime zone: America/Detroit\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] fastshap_0.1.1       randomForest_4.7-1.2 patchwork_1.3.2     \n [4] kableExtra_1.4.0     knitr_1.51           lubridate_1.9.4     \n [7] forcats_1.0.1        stringr_1.6.0        dplyr_1.1.4         \n[10] purrr_1.2.0          readr_2.1.6          tidyr_1.3.2         \n[13] tibble_3.3.0         ggplot2_4.0.1        tidyverse_2.0.0     \n[16] poLCA_1.6.0.1        MASS_7.3-65          scatterplot3d_0.3-44\n\nloaded via a namespace (and not attached):\n [1] generics_0.1.4     xml2_1.5.1         stringi_1.8.7      hms_1.1.4         \n [5] digest_0.6.39      magrittr_2.0.4     evaluate_1.0.5     grid_4.5.2        \n [9] timechange_0.3.0   RColorBrewer_1.1-3 iterators_1.0.14   fastmap_1.2.0     \n[13] foreach_1.5.2      jsonlite_2.0.0     viridisLite_0.4.2  scales_1.4.0      \n[17] codetools_0.2-20   textshaping_1.0.4  cli_3.6.5          rlang_1.1.6       \n[21] withr_3.0.2        yaml_2.3.12        otel_0.2.0         tools_4.5.2       \n[25] tzdb_0.5.0         vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n[29] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.11.1      gtable_0.3.6      \n[33] Rcpp_1.1.0         glue_1.8.0         systemfonts_1.3.1  xfun_0.55         \n[37] tidyselect_1.2.1   rstudioapi_0.17.1  farver_2.1.2       htmltools_0.5.9   \n[41] labeling_0.4.3     rmarkdown_2.30     svglite_2.2.2      compiler_4.5.2    \n[45] S7_0.2.1          \n```\n\n\n:::\n:::\n\n",
    "supporting": [
      "lca-walkthrough_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"lca-walkthrough_files/libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"lca-walkthrough_files/libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}